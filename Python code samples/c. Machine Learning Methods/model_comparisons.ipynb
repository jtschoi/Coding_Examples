{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of different ML models by MSE\n",
    "\n",
    "### Prepared by Junho Choi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Preparation for model comparisons\n",
    "\n",
    "In this section, I prepare necessary modules and the X- and Y-variables to be used in the model selection process.\n",
    "\n",
    "#### A.1. Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "## for ignoring warnings about future updates, etc.\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.2. Importing data and defining X- and Y-variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.read_csv('baseline_df.csv')\n",
    "xval_cols = ['age', 'female', 'urgency', 'urg_times_wd', 'aids_area',\n",
    "             'exploit_area', 'christian_pct', 'schooling_yn',\n",
    "             'mother', 'father', 'mother_irreg_emp', 'mother_reg_emp',\n",
    "             'father_irreg_emp', 'father_reg_emp',\n",
    "             'region_mo_inc_w_impu', 'asia', 'southame', 'centralame']\n",
    "xvals = baseline_df[xval_cols].values\n",
    "yvals = baseline_df['ever_matched'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Optimization initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_optimization(xvals, yvals, model, search_dict,\n",
    "                       randomness, model_rtn=False):\n",
    "    '''\n",
    "    Provides the best (hyper)parameters and MSE based on\n",
    "    Randomized Search CV.\n",
    "    \n",
    "    Input:\n",
    "    - xvals (np.array (2D)): values of feature variables\n",
    "    - yvals (np.array (1D)): values of dependent variable\n",
    "    - model: model initialzation (e.g., those provided)\n",
    "        by scikit-learn\n",
    "    - search_dict (dict): dictionary of hyperparameters\n",
    "        to test\n",
    "    - randomness (int): random seed\n",
    "    - model_rtn (boolean): if False, does not return the\n",
    "        \"best\" fitted model\n",
    "    \n",
    "    Output:\n",
    "    - if model_rtn is True, triple of the best hyperparmeters,\n",
    "        best MSE, and best model; if False, only the first\n",
    "        two are returned as a tuple\n",
    "    '''\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        model, param_distributions=search_dict, n_iter=200,\n",
    "        n_jobs=-1, cv=5, random_state=randomness,\n",
    "        scoring='neg_mean_squared_error')\n",
    "    \n",
    "    random_search.fit(xvals, yvals)\n",
    "    return_vars = [random_search.best_params_,\n",
    "                   -random_search.best_score_]\n",
    "    \n",
    "    if model_rtn:\n",
    "        return_vars.append(random_search)\n",
    "        \n",
    "    return return_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Hyper-parameter optimization\n",
    "\n",
    "#### C.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomness = 60615\n",
    "LR = LogisticRegression(random_state=randomness)\n",
    "param_dist_LR = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': sp_uniform(0.1, 10.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: {'C': 0.4140831117072995, 'penalty': 'l1'}\n",
      "Best score (MSE) is: 0.420782\n"
     ]
    }
   ],
   "source": [
    "LR_param, LR_score = model_optimization(xvals, yvals, LR, param_dist_LR,\n",
    "                                        randomness)\n",
    "print('Best params are:', LR_param)\n",
    "print('Best score (MSE) is:', str(round(LR_score, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(random_state=randomness)\n",
    "param_dist_DTC = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['random', 'best'],\n",
    "    'min_samples_split': list(range(2, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: {'splitter': 'random', 'min_samples_split': 9, 'criterion': 'entropy'}\n",
      "Best score (MSE) is: 0.419311\n"
     ]
    }
   ],
   "source": [
    "DTC_param, DTC_score = model_optimization(xvals, yvals, DTC,\n",
    "                                          param_dist_DTC, randomness)\n",
    "print('Best params are:', DTC_param)\n",
    "print('Best score (MSE) is:', str(round(DTC_score, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(random_state=randomness)\n",
    "param_dist_RFC = {\n",
    "    'n_estimators': sp_randint(5, 200),\n",
    "    'max_depth': sp_randint(2, 4),\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "    'min_samples_leaf': sp_randint(2, 20),\n",
    "    'max_features': sp_randint(1, 4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: {'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 5, 'min_samples_split': 15, 'n_estimators': 14}\n",
      "Best score (MSE) is: 0.394621\n"
     ]
    }
   ],
   "source": [
    "RFC_param, RFC_score = model_optimization(xvals, yvals, RFC,\n",
    "                                          param_dist_RFC, randomness)\n",
    "print('Best params are:', RFC_param)\n",
    "print('Best score (MSE) is:', str(round(RFC_score, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model = SVC(random_state=randomness, kernel='rbf')\n",
    "param_dist_SVC = {\n",
    "    'C': sp_uniform(loc=0.1, scale=10.0),\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'shrinking': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: {'C': 2.1936855213947792, 'gamma': 'auto', 'shrinking': True}\n",
      "Best score (MSE) is: 0.414478\n"
     ]
    }
   ],
   "source": [
    "SVC_param, SVC_score = model_optimization(xvals, yvals, SVC_model,\n",
    "                                          param_dist_SVC, randomness)\n",
    "print('Best params are:', SVC_param)\n",
    "print('Best score (MSE) is:', str(round(SVC_score, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.5. Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "param_dist_QDA = {\n",
    "    'reg_param': np.linspace(0, 1, 11), \n",
    "    'tol': [1.0e-6, 1.0e-5, 1.0e-4, 1.0e-3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: {'tol': 1e-06, 'reg_param': 0.8}\n",
      "Best score (MSE) is: 0.421937\n"
     ]
    }
   ],
   "source": [
    "QDA_param, QDA_score = model_optimization(xvals, yvals, QDA,\n",
    "                                          param_dist_QDA, randomness)\n",
    "print('Best params are:', QDA_param)\n",
    "print('Best score (MSE) is:', str(round(QDA_score, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.6. Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=randomness)\n",
    "param_dist_MLP = {\n",
    "    'hidden_layer_sizes': sp_randint(1, 100), \n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'alpha': sp_uniform(0.1, 10.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: {'activation': 'relu', 'alpha': 1.9360643043685588, 'hidden_layer_sizes': 51}\n",
      "Best score (MSE) is: 0.411326\n"
     ]
    }
   ],
   "source": [
    "MLP_param, MLP_score = model_optimization(xvals, yvals, MLP,\n",
    "                                          param_dist_MLP, randomness)\n",
    "print('Best params are:', MLP_param)\n",
    "print('Best score (MSE) is:', str(round(MLP_score, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Brief comment\n",
    "\n",
    "In terms of MSE, it seems that the \"best\" model (in terms of minimized mean-squared error) is the hyperparameter-tuned random forest model. However, the said MSE of the best model is not considerably lower than those of other models; perhaps there must be further considerations like addition of more relevant features, different target score for tuning, and so forth."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
